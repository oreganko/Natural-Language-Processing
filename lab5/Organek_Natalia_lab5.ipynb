{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "imported-guest",
   "metadata": {},
   "source": [
    "# Natalia Organek - lab 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "velvet-establishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import regex as re\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "impressed-literacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../lab1/ustawy'\n",
    "filenames = os.listdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "reasonable-question",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "html_regex = r'<[\\s\\S]*?>'\n",
    "\n",
    "\n",
    "for filename in filenames:\n",
    "    with open(os.path.join(directory, filename), encoding=\"UTF-8\") as f:\n",
    "        bill = f.read()\n",
    "        bill = bill.lower()\n",
    "        bill = re.sub(html_regex, '', bill)\n",
    "        bill = bill.replace('\\xad', '').replace('\\xa0', ' ')\n",
    "        \n",
    "        corpus.append(bill)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-yesterday",
   "metadata": {},
   "source": [
    "## Using KRNNT2 docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "supreme-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_krnnt(text):\n",
    "    answer = requests.post('http://localhost:9201/', data=text.encode('utf-8')).text\n",
    "    answer_words = answer.split('\\n')\n",
    "    words = [word for word in answer_words if word.startswith('\\t')]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cloudy-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_and_tag_text(text):\n",
    "    words = ask_krnnt(text)\n",
    "    return [get_lem_tag(word) for word in words]\n",
    "    \n",
    "def get_lem_tag(word):\n",
    "    splitted = word.split('\\t')\n",
    "    morf_cat = splitted[2].split(':')[0]\n",
    "    return splitted[1] + ':' + morf_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "moved-chick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ala:subst', 'chcieć:fin', 'kot:subst', ',:interp', 'Ala:subst', 'mieć:fin', 'kot:subst', 'i:conj', 'Ala:subst', 'mieć:fin', 'kot:subst', ',:interp', 'aczkolwiek:comp', 'przyjść:pant', 'z:prep', 'dwór:subst', ',:interp', 'nie:qub', 'nakarmić:praet', 'on:ppron3', '.:interp', 'ad:brev', '.:interp', '3:adj', 'dziennik:brev', '.:interp', 'u:prep']\n"
     ]
    }
   ],
   "source": [
    "lemmatized_corpus = lemmatize_and_tag_text('Ala chce kota, Ala ma kota i Ala ma kota, aczkolwiek przyszedłszy z dworu, nie nakarmiła go. \\n\\n\\n ad.3 dz.u')\n",
    "print(lemmatized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "humanitarian-threat",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1179/1179 [1:00:34<00:00,  3.08s/it]\n"
     ]
    }
   ],
   "source": [
    "lemmatized_corpus = []\n",
    "for corpus_text in tqdm(corpus):\n",
    "    lemmatized_corpus.extend(lemmatize_and_tag_text(corpus_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-queue",
   "metadata": {},
   "source": [
    "## Using the tagged corpus compute bigram statistic for the tokens containing:\n",
    " - lemmatized, downcased word\n",
    " - morphosyntactic category of the word (subst, fin, adj, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "future-universe",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = [b for b in nltk.bigrams(lemmatized_corpus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "efficient-approach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dziennik:brev', '.:interp'),\n",
       " ('.:interp', 'u:prep'),\n",
       " ('u:prep', '.:interp'),\n",
       " ('.:interp', 'z:prep'),\n",
       " ('z:prep', '1998:adj'),\n",
       " ('1998:adj', 'rok:brev'),\n",
       " ('rok:brev', '.:interp'),\n",
       " ('.:interp', 'numer:brev'),\n",
       " ('numer:brev', '75:num'),\n",
       " ('75:num', ',:interp')]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "established-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters_reg = r'^\\p{Letter}+$'\n",
    "\n",
    "def token_valid(token):\n",
    "    return re.match(letters_reg, token.split(':')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "caroline-desire",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_count = Counter(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "significant-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_bigrams = Counter({\n",
    "    (t1, t2): count for (t1, t2), count in bigrams_count.items() if token_valid(t1) and token_valid(t2)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "existing-clone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('w:prep', 'artykuł:brev'), 32038),\n",
       " (('o:prep', 'który:adj'), 28658),\n",
       " (('który:adj', 'mowa:subst'), 28540),\n",
       " (('mowa:subst', 'w:prep'), 28473),\n",
       " (('w:prep', 'ustęp:brev'), 23536),\n",
       " (('z:prep', 'dzień:subst'), 11360),\n",
       " (('otrzymywać:fin', 'brzmienie:subst'), 10535),\n",
       " (('określić:ppas', 'w:prep'), 9693),\n",
       " (('do:prep', 'sprawa:subst'), 8718),\n",
       " (('ustawa:subst', 'z:prep'), 8625),\n",
       " (('właściwy:adj', 'do:prep'), 8536),\n",
       " (('i:conj', 'numer:brev'), 8435),\n",
       " (('dodawać:fin', 'się:qub'), 8196),\n",
       " (('minister:subst', 'właściwy:adj'), 7936),\n",
       " (('w:prep', 'brzmienie:subst'), 7278)]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_bigrams.most_common()[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "brutal-transmission",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tokens = Counter([token for token in lemmatized_corpus if token_valid(token)])\n",
    "tokens_len = sum(valid_tokens.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "portuguese-bicycle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('w:prep', 202691),\n",
       " ('i:conj', 90001),\n",
       " ('z:prep', 87985),\n",
       " ('artykuł:brev', 83766),\n",
       " ('o:prep', 64714),\n",
       " ('do:prep', 60758),\n",
       " ('ustęp:brev', 53338),\n",
       " ('na:prep', 50647),\n",
       " ('który:adj', 49385),\n",
       " ('się:qub', 45888),\n",
       " ('lub:conj', 45800),\n",
       " ('pozycja:brev', 45216),\n",
       " ('numer:brev', 44940),\n",
       " ('oraz:conj', 33564),\n",
       " ('rok:brev', 33137)]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_tokens.most_common()[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-obligation",
   "metadata": {},
   "source": [
    "## Compute LLR statistic for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "particular-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormEntropy(counts):\n",
    "    '''Computes the entropy of a list of counts scaled by the sum of the counts. If the inputs sum to one, this is just the normal definition of entropy'''\n",
    "    total = float(sum(counts))\n",
    "    # Note tricky way to avoid 0*log(0)\n",
    "    return -sum([k * math.log(k/total + (k==0)) for k in counts])\n",
    "\n",
    "def llr_2x2(k11, k12, k21, k22):\n",
    "    '''Special case of llr with a 2x2 table'''\n",
    "    return 2 * (denormEntropy([k11+k12, k21+k22]) +\n",
    "                denormEntropy([k11+k21, k12+k22]) -\n",
    "                denormEntropy([k11, k12, k21, k22]))\n",
    "\n",
    "def llr(word1, word2):\n",
    "    k11 = valid_bigrams[(word1, word2)]\n",
    "    k12 = valid_tokens[word2] - k11\n",
    "    k21 = valid_tokens[word1] - k11\n",
    "    k22 = tokens_len - k12 - k21 - k11\n",
    "    return llr_2x2(k11, k12, k21, k22)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "flush-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_llr = {(w1, w2): llr(w1, w2) for (w1, w2) in valid_bigrams.keys()}\n",
    "bigrams_llr_list = [b for b in bigrams_llr.items()]\n",
    "bigrams_llr_list.sort(key = lambda a: (-a[1], a[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "cutting-aging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('który:adj', 'mowa:subst'), 262456.2132033333),\n",
       " (('o:prep', 'który:adj'), 178228.44435145345),\n",
       " (('mowa:subst', 'w:prep'), 163972.24869889254),\n",
       " (('otrzymywać:fin', 'brzmienie:subst'), 116130.94667432937),\n",
       " (('w:prep', 'artykuł:brev'), 82807.20136142336),\n",
       " (('minister:subst', 'właściwy:adj'), 71774.7355501341),\n",
       " (('dodawać:fin', 'się:qub'), 70893.8407511349),\n",
       " (('w:prep', 'ustęp:brev'), 67792.45630358532),\n",
       " (('stosować:fin', 'się:qub'), 56164.454882081365),\n",
       " (('droga:subst', 'rozporządzenie:subst'), 54199.295313896466)]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_llr_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-coaching",
   "metadata": {},
   "source": [
    "## Partition the entries based on the syntactic categories of the words,\n",
    "i.e. all bigrams having the form of w1:adj w2:subst should be placed in one partition (the order of the words may not be changed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "violent-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category(word):\n",
    "    return word.split(':')[1]\n",
    "\n",
    "def get_bigram_category(bigram):\n",
    "    return get_category(bigram[0]), get_category(bigram[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "linear-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions_dict = {}\n",
    "for (bigram, llr) in bigrams_llr_list:\n",
    "    category = get_bigram_category(bigram)\n",
    "    if partitions_dict.get(category):\n",
    "        partitions_dict[category].append((bigram, llr))\n",
    "    else:\n",
    "        partitions_dict[category] = [(bigram, llr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "linear-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions_count = [(key, len(vals)) for key, vals in partitions_dict.items()]\n",
    "partitions_count.sort(key = lambda a: (-a[1], a[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "diverse-greensboro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('subst', 'subst'), 47929),\n",
       " (('subst', 'adj'), 27162),\n",
       " (('adj', 'subst'), 26170),\n",
       " (('subst', 'fin'), 16160),\n",
       " (('ger', 'subst'), 15587),\n",
       " (('prep', 'subst'), 12302),\n",
       " (('subst', 'prep'), 11375),\n",
       " (('subst', 'ppas'), 10708),\n",
       " (('fin', 'subst'), 8815),\n",
       " (('adj', 'fin'), 8701)]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partitions_count[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "prospective-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_partitions = {name: partitions_dict[name] for name, count in partitions_count[:10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-politics",
   "metadata": {},
   "source": [
    "## Use the computed LLR measure to select 5 bigrams for each of the largest categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "permanent-greek",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('subst', 'subst')\n",
      "\t (('droga:subst', 'rozporządzenie:subst'), 54199.295313896466)\n",
      "\t (('skarb:subst', 'państwo:subst'), 22938.521533561434)\n",
      "\t (('rada:subst', 'minister:subst'), 15832.100085449114)\n",
      "\t (('terytorium:subst', 'rzeczpospolita:subst'), 14825.037587484869)\n",
      "\t (('ochrona:subst', 'środowisko:subst'), 14682.174867568887)\n",
      "('subst', 'adj')\n",
      "\t (('minister:subst', 'właściwy:adj'), 71774.7355501341)\n",
      "\t (('rzeczpospolita:subst', 'polski:adj'), 44555.91107030348)\n",
      "\t (('jednostka:subst', 'organizacyjny:adj'), 25135.72813975817)\n",
      "\t (('samorząd:subst', 'terytorialny:adj'), 24068.68876693108)\n",
      "\t (('produkt:subst', 'leczniczy:adj'), 22191.420445811877)\n",
      "('adj', 'subst')\n",
      "\t (('który:adj', 'mowa:subst'), 262456.2132033333)\n",
      "\t (('niniejszy:adj', 'ustawa:subst'), 21091.35283317353)\n",
      "\t (('następujący:adj', 'zmiana:subst'), 18007.764785394815)\n",
      "\t (('odrębny:adj', 'przepis:subst'), 12445.36233583247)\n",
      "\t (('walny:adj', 'zgromadzenie:subst'), 9833.689830195068)\n",
      "('subst', 'fin')\n",
      "\t (('ustawa:subst', 'wchodzić:fin'), 9071.729771287704)\n",
      "\t (('kropka:subst', 'zastępować:fin'), 7717.953174045906)\n",
      "\t (('treść:subst', 'oznaczać:fin'), 2663.3275733819937)\n",
      "\t (('minister:subst', 'określić:fin'), 2588.154917006148)\n",
      "\t (('sąd:subst', 'móc:fin'), 1408.260454129777)\n",
      "('ger', 'subst')\n",
      "\t (('zasięgnąć:ger', 'opinia:subst'), 11718.803168630315)\n",
      "\t (('pozbawić:ger', 'wolność:subst'), 11649.897566032741)\n",
      "\t (('wykonywać:ger', 'zawód:subst'), 5844.653098166367)\n",
      "\t (('zawrzeć:ger', 'umowa:subst'), 5375.315919406727)\n",
      "\t (('wszcząć:ger', 'postępowanie:subst'), 5299.1116169402085)\n",
      "('prep', 'subst')\n",
      "\t (('do:prep', 'sprawa:subst'), 49720.51012212434)\n",
      "\t (('z:prep', 'dzień:subst'), 48745.009215768194)\n",
      "\t (('na:prep', 'podstawa:subst'), 48682.27022256469)\n",
      "\t (('w:prep', 'droga:subst'), 35042.77063440066)\n",
      "\t (('od:prep', 'dzień:subst'), 32037.65173509851)\n",
      "('subst', 'prep')\n",
      "\t (('mowa:subst', 'w:prep'), 163972.24869889254)\n",
      "\t (('ustawa:subst', 'z:prep'), 33372.931786611676)\n",
      "\t (('miesiąc:subst', 'od:prep'), 11157.587486098637)\n",
      "\t (('wniosek:subst', 'o:prep'), 10779.080079527339)\n",
      "\t (('dzień:subst', 'od:prep'), 10680.517043199274)\n",
      "('subst', 'ppas')\n",
      "\t (('zasada:subst', 'określić:ppas'), 7860.584593424399)\n",
      "\t (('ustawa:subst', 'zmieniać:ppas'), 5439.039993745799)\n",
      "\t (('czyn:subst', 'zabronić:ppas'), 4616.427891329073)\n",
      "\t (('brzmienie:subst', 'nadać:ppas'), 3530.0157474210137)\n",
      "\t (('warunek:subst', 'określić:ppas'), 3006.390802213544)\n",
      "('fin', 'subst')\n",
      "\t (('otrzymywać:fin', 'brzmienie:subst'), 116130.94667432937)\n",
      "\t (('podlegać:fin', 'kara:subst'), 9158.84534273675)\n",
      "\t (('mieć:fin', 'prawo:subst'), 4852.456971896434)\n",
      "\t (('mieć:fin', 'zastosowanie:subst'), 4352.064493482394)\n",
      "\t (('zachowywać:fin', 'moc:subst'), 3726.955109709561)\n",
      "('adj', 'fin')\n",
      "\t (('obowiązany:adj', 'być:fin'), 2850.163186542457)\n",
      "\t (('który:adj', 'wchodzić:fin'), 1776.568074021954)\n",
      "\t (('publiczny:adj', 'określić:fin'), 1271.7240728932666)\n",
      "\t (('wewnętrzny:adj', 'określić:fin'), 1177.3162618982315)\n",
      "\t (('narodowy:adj', 'określić:fin'), 1122.9450059626834)\n"
     ]
    }
   ],
   "source": [
    "for partition, words in top_10_partitions.items():\n",
    "    print(partition)\n",
    "    for word in words[:5]:\n",
    "        print('\\t', word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-graph",
   "metadata": {},
   "source": [
    "## Using the results from the previous step answer the following questions:\n",
    "### What types of bigrams have been found?\n",
    "Prawie wszystkie bigramy (wśród najpopularniejszych) zawierają rzeczownik, w większości wraz z jego określeniem w różnych klasach morfologicznych (np. rzeczownik z przymiotnikiem [symetrycznie przymiotnik z rzeczownikiem], rzeczownik z rzeczownikiem [największa klasa], przymiotnik z rzeczownikiem odczasownikowym, imiesłowem przym. biernym itp.) występują również połączenia rzeczownik-przyimek (symetrycznie przyimek-rzeczownik), rzeczownik-czasownik, czasownik rzeczownik.\n",
    "\n",
    "Największ klasa bigramów które nie zawierają rzeczownika to przymiotnik-czasownik(non-past), jednak patrząc na przykłady tej klasy - są to części min. trigramów (... obowiązany jest, ... który wchodzi, ... wewnętrzny określa, itp, inaczej nie znamy pełnego podmiotu).\n",
    "\n",
    "\n",
    "### Which of the category-pairs indicate valuable multiword expressions? Do they have anything in common?\n",
    "Są to wyrażenia, które mają przynajmniej jeden rzeczownik. Pary rzeczownik-rzeczownik to są praktycznie tylko prawidłowe wyrażenia wielowyrazowe (oczywiście patrząc na te przykłady z top-LLR), np. skarb państwa, ohrona środowiska.\n",
    "\n",
    "Ciekawa rzecz jest przy bigramach rzeczownik-przymniotnik, gdyż w tej kolejności również są niemal tylko MWE, (minister właściwy, produkt leczniczy), ale gdy kolejność zostaje odwócona (przymiotnik-rzeczownik), to pojawiają się już bigramy, które ciężko zakwalifikować jako MWE (który - mowa), oczywiście istnieją i takie (walne zgromadzenie) i jest ich też dość dużo.\n",
    "\n",
    "Jeśli chodzi o pary rzeczownik-czasownik w formie prostej(fin) i czasownik-rzeczownik, to trudno je kwalifikować jako MWE, w większości są to pary słów często stojące obok siebie, ale niemające dodatkowego/innego znaczenia. Podobnie jest w przypadku wyrażeń z przyimkami. Podobnie ma się rzecz z parami rzeczownik-rzeczownik odczasownikowy czy rzeczownik-imiesłów przymiotnikowy bierny.\n",
    "\n",
    "Przyimki z rzeczownikami nie tworzą MWE, tak samo jak przymiotnik z czasownikiem(fin) - w tym wypadku, tak jak pisałam wcześniej, są to głównie części trigramów, więc ciężko oszukiwać się w nich MWE.\n",
    "\n",
    "\n",
    "### Which signal: LLR score or syntactic category is more useful for determining genuine multiword expressions?\n",
    "Myślę że ich połączenie działa dosyć dobrze, tzn. najpierw wyodrębnienie kategorii morfologicznych, a dopiero w ich obrębie sortowanie po wyniku LLR. Wyodrębnienie kategorii jest kluczowe, gdyż widać, że niektóre ich połączenia mają tendencję do tworzenia związków frazeologicznych, a niektóre po prostu nie. W poprzednim laboratorium wyniki po samym LLR były mierne - po prostu były to częste połączenia wyrazowe, ale mało miały wspólnego z MWE. W dodatku nie zastosowaliśmy wtedy lematyzacji, więc były do siebie bardzo podobne.\n",
    "\n",
    "\n",
    "\n",
    "### Can you describe a different use-case where the morphosyntactic category is useful for resolving a real-world problem?\n",
    "\n",
    "Wyszukiwanie nazw własnych w tekście; sprawdzanie poprawności budowanych zdań, albo nawet ich rozbudowywanie (podpowiedzi od aplikacji, jakie słowa/wyrażenia mogłyby pasować, wcześniej oczywiście system musiałby wiedzieć jakie kategorie mogą stać po jakich, potem jakie są częste połączenia konkretnych wyrazów)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-injection",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
